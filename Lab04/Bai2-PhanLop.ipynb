{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898291f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:12:18 WARN Utils: Your hostname, sheepb-HP-Pavilion-Notebook resolves to a loopback address: 127.0.1.1; using 192.168.1.9 instead (on interface wlo1)\n",
      "22/01/21 17:12:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lab04-PhanLop').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0819a09",
   "metadata": {},
   "source": [
    "## Đọc và xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Lab04-Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c01806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(data_path + 'mushrooms.csv', inferSchema=True, header=True, sep=',')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccfb6d",
   "metadata": {},
   "source": [
    "## a. Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = df.columns\n",
    "label_col = 'class'\n",
    "features_col.remove(label_col)\n",
    "featuresIndexer = [StringIndexer(inputCol=column, outputCol=column+\"Indexer\").fit(df) \n",
    "                       for column in features_col]\n",
    "    \n",
    "for featureIndexer in featuresIndexer:\n",
    "    df = featureIndexer.transform(df)\n",
    "        \n",
    "features_col = [feature_col + \"Indexer\" for feature_col in features_col]\n",
    "vec_assembler = VectorAssembler(inputCols = features_col , outputCol = \"features\")\n",
    "features_df = vec_assembler.transform(df).select('features', label_col)\n",
    "\n",
    "# featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(features_df)\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\").fit(features_df)\n",
    "# features_df = featureIndexer.transform(features_df)\n",
    "features_df = labelIndexer.transform(features_df)\n",
    "    \n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d357ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu ra thành train, test theo tỉ lệ 80:20\n",
    "train, test = features_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0d4ea",
   "metadata": {},
   "source": [
    "## b. Mô hình decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, maxBins=32)\n",
    "model_dct = decision_tree.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de1bb7",
   "metadata": {},
   "source": [
    "## c. Mô hình random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82419e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_cls = RandomForestClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, numTrees=10)\n",
    "model_rdf = rdf_cls.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a5c44",
   "metadata": {},
   "source": [
    "## d. Đánh giá 2 mô hình trên tập kiểm thử"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_ds = model_dct.transform(test)\n",
    "test_pred_rdf = model_rdf.transform(test)\n",
    "# accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "accuracy_ds = evaluator.evaluate(test_pred_ds)\n",
    "accuracy_rdf = evaluator.evaluate(test_pred_rdf)\n",
    "\n",
    "print(\"Accuracy on test\")\n",
    "print(f\"- accuracy of decisionTree: {accuracy_ds}\")\n",
    "print(f\"- accuracy of RandomForest: {accuracy_rdf}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3430b9",
   "metadata": {},
   "source": [
    "## e. Sử dụng Pipeline để thiết lập các bước trên thành một bước duy nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d0e79",
   "metadata": {},
   "source": [
    "- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(data_path + 'mushrooms.csv', inferSchema=True, header=True, sep=',')\n",
    "\n",
    "# preprocessing\n",
    "features_col = df.columns\n",
    "features_col.remove(label_col)\n",
    "featuresIndexer = [StringIndexer(inputCol=column, outputCol=column+\"Indexer\").fit(df) \n",
    "                       for column in features_col]\n",
    "    \n",
    "for featureIndexer in featuresIndexer:\n",
    "    df = featureIndexer.transform(df)\n",
    "        \n",
    "features_col = [feature_col + \"Indexer\" for feature_col in features_col]\n",
    "vec_assembler = VectorAssembler(inputCols = features_col , outputCol = \"features\")\n",
    "features_df = vec_assembler.transform(df).select('features', label_col)\n",
    "    \n",
    "\n",
    "# split data    \n",
    "train_df, test_df = features_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Make pipeline\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\").fit(features_df)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, maxBins=32)\n",
    "\n",
    "pipeline_dct = Pipeline(stages=[labelIndexer, decision_tree])\n",
    "\n",
    "params_dct = ParamGridBuilder().addGrid(decision_tree.maxDepth, [5, 10, 20])\\\n",
    "                            .addGrid(decision_tree.maxBins, [ 15, 32])\\\n",
    "                            .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "tvs_dct = TrainValidationSplit().setTrainRatio(0.8)\\\n",
    "                            .setEstimatorParamMaps(params_dct)\\\n",
    "                            .setEstimator(pipeline_dct)\\\n",
    "                            .setEvaluator(evaluator)\n",
    "\n",
    "tvsFitted = tvs_dct.fit(train_df)\n",
    "evaluator.evaluate(tvsFitted.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9080a1",
   "metadata": {},
   "source": [
    "- randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_cls = RandomForestClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, numTrees=10)\n",
    "\n",
    "pipeline_rdf = Pipeline(stages=[labelIndexer, rdf_cls])\n",
    "\n",
    "params_rdf = ParamGridBuilder().addGrid(rdf_cls.maxDepth, [5, 10, 20])\\\n",
    "                            .addGrid(rdf_cls.numTrees, [ 5, 10, 15])\\\n",
    "                            .build()\n",
    "\n",
    "tvs_dct = TrainValidationSplit().setTrainRatio(0.8)\\\n",
    "                            .setEstimatorParamMaps(params_rdf)\\\n",
    "                            .setEstimator(pipeline_rdf)\\\n",
    "                            .setEvaluator(evaluator)\n",
    "\n",
    "tvsFitted = tvs_dct.fit(train_df)\n",
    "evaluator.evaluate(tvsFitted.transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb549b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
