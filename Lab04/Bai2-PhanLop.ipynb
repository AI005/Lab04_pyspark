{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2432a9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:12:18 WARN Utils: Your hostname, sheepb-HP-Pavilion-Notebook resolves to a loopback address: 127.0.1.1; using 192.168.1.9 instead (on interface wlo1)\n",
      "22/01/21 17:12:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/sheepb/code/jupyter_dir/jupyter_env/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/21 17:12:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/21 17:12:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/01/21 17:12:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lab04-PhanLop').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d27be",
   "metadata": {},
   "source": [
    "## Đọc và xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2cac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Lab04-Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec410c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|class|cap-shape|cap-surface|cap-color|bruises|odor|gill-attachment|gill-spacing|gill-size|gill-color|stalk-shape|stalk-root|stalk-surface-above-ring|stalk-surface-below-ring|stalk-color-above-ring|stalk-color-below-ring|veil-type|veil-color|ring-number|ring-type|spore-print-color|population|habitat|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        y|      t|   a|              f|           c|        b|         k|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
      "|    e|        b|          s|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      m|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        g|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
      "|    e|        x|          y|        y|      t|   a|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         n|      g|\n",
      "|    e|        b|          s|        w|      t|   a|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         n|      m|\n",
      "|    e|        b|          y|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      m|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         p|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         v|      g|\n",
      "|    e|        b|          s|        y|      t|   a|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      m|\n",
      "|    e|        x|          y|        y|      t|   l|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
      "|    e|        x|          y|        y|      t|   a|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      m|\n",
      "|    e|        b|          s|        y|      t|   a|              f|           c|        b|         w|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      g|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         v|      u|\n",
      "|    e|        x|          f|        n|      f|   n|              f|           w|        b|         n|          t|         e|                       s|                       f|                     w|                     w|        p|         w|          o|        e|                k|         a|      g|\n",
      "|    e|        s|          f|        g|      f|   n|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         y|      u|\n",
      "|    e|        f|          f|        w|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      g|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      u|\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      u|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(data_path + 'mushrooms.csv', inferSchema=True, header=True, sep=',')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b3040",
   "metadata": {},
   "source": [
    "## a. Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a94af4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/21 17:12:42 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|class|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(22,[1,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[1,2,3,4,8,9,...|    e|         0.0|\n",
      "|(22,[0,1,2,3,4,8,...|    e|         0.0|\n",
      "|(22,[2,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[1,2,6,8,10,1...|    e|         0.0|\n",
      "|(22,[2,3,4,8,9,10...|    e|         0.0|\n",
      "|(22,[0,1,2,3,4,8,...|    e|         0.0|\n",
      "|(22,[0,2,3,4,8,9,...|    e|         0.0|\n",
      "|(22,[2,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[0,1,2,3,4,8,...|    e|         0.0|\n",
      "|(22,[2,3,4,8,9,10...|    e|         0.0|\n",
      "|(22,[2,3,4,8,9,10...|    e|         0.0|\n",
      "|(22,[0,1,2,3,4,8,...|    e|         0.0|\n",
      "|(22,[2,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[1,6,8,10,12,...|    e|         0.0|\n",
      "|(22,[0,1,2,7,8,9,...|    e|         0.0|\n",
      "|(22,[0,1,2,6,8,10...|    e|         0.0|\n",
      "|(22,[1,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[2,3,4,7,8,9,...|    p|         1.0|\n",
      "|(22,[1,3,4,7,8,9,...|    p|         1.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_col = df.columns\n",
    "label_col = 'class'\n",
    "features_col.remove(label_col)\n",
    "featuresIndexer = [StringIndexer(inputCol=column, outputCol=column+\"Indexer\").fit(df) \n",
    "                       for column in features_col]\n",
    "    \n",
    "for featureIndexer in featuresIndexer:\n",
    "    df = featureIndexer.transform(df)\n",
    "        \n",
    "features_col = [feature_col + \"Indexer\" for feature_col in features_col]\n",
    "vec_assembler = VectorAssembler(inputCols = features_col , outputCol = \"features\")\n",
    "features_df = vec_assembler.transform(df).select('features', label_col)\n",
    "\n",
    "# featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(features_df)\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\").fit(features_df)\n",
    "# features_df = featureIndexer.transform(features_df)\n",
    "features_df = labelIndexer.transform(features_df)\n",
    "    \n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3556c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu ra thành train, test theo tỉ lệ 80:20\n",
    "train, test = features_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be9ece",
   "metadata": {},
   "source": [
    "## b. Mô hình decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e4ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 73:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, maxBins=32)\n",
    "model_dct = decision_tree.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2294eb",
   "metadata": {},
   "source": [
    "## c. Mô hình random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09568972",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_cls = RandomForestClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, numTrees=10)\n",
    "model_rdf = rdf_cls.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09133e",
   "metadata": {},
   "source": [
    "## d. Đánh giá 2 mô hình trên tập kiểm thử"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebad28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test\n",
      "- accuracy of decisionTree: 1.0\n",
      "- accuracy of RandomForest: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_pred_ds = model_dct.transform(test)\n",
    "test_pred_rdf = model_rdf.transform(test)\n",
    "# accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "accuracy_ds = evaluator.evaluate(test_pred_ds)\n",
    "accuracy_rdf = evaluator.evaluate(test_pred_rdf)\n",
    "\n",
    "print(\"Accuracy on test\")\n",
    "print(f\"- accuracy of decisionTree: {accuracy_ds}\")\n",
    "print(f\"- accuracy of RandomForest: {accuracy_rdf}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49a135",
   "metadata": {},
   "source": [
    "## e. Sử dụng Pipeline để thiết lập các bước trên thành một bước duy nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db794bc1",
   "metadata": {},
   "source": [
    "- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52836ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993823347745522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(data_path + 'mushrooms.csv', inferSchema=True, header=True, sep=',')\n",
    "\n",
    "# preprocessing\n",
    "features_col = df.columns\n",
    "features_col.remove(label_col)\n",
    "featuresIndexer = [StringIndexer(inputCol=column, outputCol=column+\"Indexer\").fit(df) \n",
    "                       for column in features_col]\n",
    "    \n",
    "for featureIndexer in featuresIndexer:\n",
    "    df = featureIndexer.transform(df)\n",
    "        \n",
    "features_col = [feature_col + \"Indexer\" for feature_col in features_col]\n",
    "vec_assembler = VectorAssembler(inputCols = features_col , outputCol = \"features\")\n",
    "features_df = vec_assembler.transform(df).select('features', label_col)\n",
    "    \n",
    "\n",
    "# split data    \n",
    "train_df, test_df = features_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Make pipeline\n",
    "labelIndexer = StringIndexer(inputCol=label_col, outputCol=\"indexedLabel\").fit(features_df)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, maxBins=32)\n",
    "\n",
    "pipeline_dct = Pipeline(stages=[labelIndexer, decision_tree])\n",
    "\n",
    "params_dct = ParamGridBuilder().addGrid(decision_tree.maxDepth, [5, 10, 20])\\\n",
    "                            .addGrid(decision_tree.maxBins, [ 15, 32])\\\n",
    "                            .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "tvs_dct = TrainValidationSplit().setTrainRatio(0.8)\\\n",
    "                            .setEstimatorParamMaps(params_dct)\\\n",
    "                            .setEstimator(pipeline_dct)\\\n",
    "                            .setEvaluator(evaluator)\n",
    "\n",
    "tvsFitted = tvs_dct.fit(train_df)\n",
    "evaluator.evaluate(tvsFitted.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ee093",
   "metadata": {},
   "source": [
    "- randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090d8916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993823347745522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_cls = RandomForestClassifier(labelCol='indexedLabel', featuresCol='features', maxDepth=20, numTrees=10)\n",
    "\n",
    "pipeline_rdf = Pipeline(stages=[labelIndexer, rdf_cls])\n",
    "\n",
    "params_rdf = ParamGridBuilder().addGrid(rdf_cls.maxDepth, [5, 10, 20])\\\n",
    "                            .addGrid(rdf_cls.numTrees, [ 5, 10, 15])\\\n",
    "                            .build()\n",
    "\n",
    "tvs_dct = TrainValidationSplit().setTrainRatio(0.8)\\\n",
    "                            .setEstimatorParamMaps(params_rdf)\\\n",
    "                            .setEstimator(pipeline_rdf)\\\n",
    "                            .setEvaluator(evaluator)\n",
    "\n",
    "tvsFitted = tvs_dct.fit(train_df)\n",
    "evaluator.evaluate(tvsFitted.transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42e90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
